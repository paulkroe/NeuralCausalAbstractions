{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b755657a-cc12-4311-b62a-81b88407d82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158c9109-394a-40d8-acf5-e4b3b5f8a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ca0303-db40-4741-bad3-98fb9366a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2\n",
      "Contents: ['HAM10000_images_part_1', 'HAM10000_images_part_2', 'HAM10000_metadata.csv', 'ham10000_images_part_1', 'ham10000_images_part_2', 'hmnist_28_28_L.csv', 'hmnist_28_28_RGB.csv', 'hmnist_8_8_L.csv', 'hmnist_8_8_RGB.csv']\n",
      "Using device: cuda\n",
      "Found image directories: ['/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_images_part_1', '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_images_part_2', '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/ham10000_images_part_1', '/root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/ham10000_images_part_2']\n",
      "Metadata CSV: /root/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2/HAM10000_metadata.csv\n",
      "Selected classes: ['nv', 'mel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 1/50: 100%|██████████| 56/56 [00:06<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 2/50: 100%|██████████| 56/56 [00:05<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 5.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 3/50: 100%|██████████| 56/56 [00:05<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 5.5951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 4/50: 100%|██████████| 56/56 [00:05<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 5.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 5/50: 100%|██████████| 56/56 [00:05<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 5.5622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 6/50: 100%|██████████| 56/56 [00:05<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 5.4811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 7/50: 100%|██████████| 56/56 [00:05<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 5.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 8/50: 100%|██████████| 56/56 [00:05<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 5.4544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 9/50: 100%|██████████| 56/56 [00:05<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 5.4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 10/50: 100%|██████████| 56/56 [00:06<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 5.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 11/50: 100%|██████████| 56/56 [00:05<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 5.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 12/50: 100%|██████████| 56/56 [00:06<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 5.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 13/50: 100%|██████████| 56/56 [00:05<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 5.3803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 14/50: 100%|██████████| 56/56 [00:05<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 5.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 15/50: 100%|██████████| 56/56 [00:05<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 5.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 16/50: 100%|██████████| 56/56 [00:05<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 5.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 17/50: 100%|██████████| 56/56 [00:06<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 5.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 18/50: 100%|██████████| 56/56 [00:05<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 5.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 19/50: 100%|██████████| 56/56 [00:05<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 5.3615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 20/50: 100%|██████████| 56/56 [00:05<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 5.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 21/50: 100%|██████████| 56/56 [00:06<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 5.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 22/50: 100%|██████████| 56/56 [00:06<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 5.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 23/50: 100%|██████████| 56/56 [00:05<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 5.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 24/50: 100%|██████████| 56/56 [00:05<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 5.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 25/50: 100%|██████████| 56/56 [00:05<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 5.3724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 26/50: 100%|██████████| 56/56 [00:06<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 5.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 27/50: 100%|██████████| 56/56 [00:05<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 5.3573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 28/50: 100%|██████████| 56/56 [00:05<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 5.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 29/50: 100%|██████████| 56/56 [00:05<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 5.3609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 30/50: 100%|██████████| 56/56 [00:05<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 5.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 31/50: 100%|██████████| 56/56 [00:06<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 5.3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 32/50: 100%|██████████| 56/56 [00:05<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 5.3494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 33/50: 100%|██████████| 56/56 [00:05<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 5.3525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 34/50: 100%|██████████| 56/56 [00:06<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 5.3614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 35/50: 100%|██████████| 56/56 [00:06<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 5.3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 36/50: 100%|██████████| 56/56 [00:06<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 5.3495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 37/50: 100%|██████████| 56/56 [00:05<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 5.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 38/50: 100%|██████████| 56/56 [00:06<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 5.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 39/50: 100%|██████████| 56/56 [00:05<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 5.3559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 40/50: 100%|██████████| 56/56 [00:06<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 5.3427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 41/50: 100%|██████████| 56/56 [00:06<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 5.3464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 42/50: 100%|██████████| 56/56 [00:06<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 5.3481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 43/50: 100%|██████████| 56/56 [00:05<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 5.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 44/50: 100%|██████████| 56/56 [00:06<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 5.3421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 45/50: 100%|██████████| 56/56 [00:05<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 5.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 46/50: 100%|██████████| 56/56 [00:06<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 5.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 47/50: 100%|██████████| 56/56 [00:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 5.3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 48/50: 100%|██████████| 56/56 [00:06<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 5.3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 49/50: 100%|██████████| 56/56 [00:05<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 5.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimCLR Epoch 50/50: 100%|██████████| 56/56 [00:05<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 5.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract Embs: 100%|██████████| 56/56 [00:03<00:00, 18.25it/s]\n",
      "Extract Embs: 100%|██████████| 14/14 [00:01<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Epoch 1, Loss: 0.7430\n",
      "Classifier Epoch 2, Loss: 0.7108\n",
      "Classifier Epoch 3, Loss: 0.6840\n",
      "Classifier Epoch 4, Loss: 0.6625\n",
      "Classifier Epoch 5, Loss: 0.6438\n",
      "Train Acc: 0.699438202247191\n",
      "Test  Acc: 0.726457399103139\n",
      "Train class-wise accuracy: {'nv': 0.7222222222222222, 'mel': 0.6770601336302895}\n",
      "Test  class-wise accuracy: {'nv': 0.7316017316017316, 'mel': 0.7209302325581395}\n",
      "Saved all embeddings and labels to ham10000_embeddings.npz (compressed NPZ)\n"
     ]
    }
   ],
   "source": [
    "# 0. Setup, download, and data loading via KaggleHub\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import kagglehub  # ensure kagglehub is installed and configured\n",
    "\n",
    "# 0.1 Download the HAM10000 dataset via KaggleHub\n",
    "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
    "print(\"Dataset directory:\", path)\n",
    "print(\"Contents:\", os.listdir(path))\n",
    "\n",
    "# 0.2 Set seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 0.3 Identify image subdirectories\n",
    "dirs = [\n",
    "    \"HAM10000_images_part_1\",\"HAM10000_images_part_2\",\n",
    "    \"ham10000_images_part_1\",\"ham10000_images_part_2\"\n",
    "]\n",
    "image_dirs = [os.path.join(path, d) for d in dirs if os.path.isdir(os.path.join(path, d))]\n",
    "print(\"Found image directories:\", image_dirs)\n",
    "\n",
    "# 0.4 Path to metadata CSV\n",
    "metadata_csv = os.path.join(path, \"HAM10000_metadata.csv\")\n",
    "print(\"Metadata CSV:\", metadata_csv)\n",
    "\n",
    "# 0.5 Dataset class (no transform) for contrastive pairs\n",
    "def make_raw_dataset(transform=None):\n",
    "    class HAM10000Raw(Dataset):\n",
    "        def __init__(self, metadata_csv, image_dirs):\n",
    "            self.df = pd.read_csv(metadata_csv)\n",
    "            self.image_dirs = image_dirs\n",
    "            self.transform = transform\n",
    "            self.classes = sorted(self.df['dx'].unique())\n",
    "            self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        def __len__(self): return len(self.df)\n",
    "        def __getitem__(self, idx):\n",
    "            row = self.df.iloc[idx]\n",
    "            img_id = row['image_id']\n",
    "            img_path = next((os.path.join(d, f\"{img_id}.jpg\") for d in self.image_dirs\n",
    "                            if os.path.isfile(os.path.join(d, f\"{img_id}.jpg\"))), None)\n",
    "            if img_path is None:\n",
    "                raise FileNotFoundError(f\"Image for ID {img_id} not found\")\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return img, self.class_to_idx[row['dx']]\n",
    "    return HAM10000Raw(metadata_csv, image_dirs)\n",
    "\n",
    "# 0.6 Raw dataset (PIL images) and Eval dataset (tensor transforms)\n",
    "raw_dataset = make_raw_dataset()\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# We'll apply basic_transform later via a separate Dataset subclass\n",
    "\n",
    "# 1. Balance top-2 classes on raw_dataset.df\n",
    "dx_counts = raw_dataset.df['dx'].value_counts()\n",
    "top2 = dx_counts.index[:2].tolist()\n",
    "print('Selected classes:', top2)\n",
    "min_ct = dx_counts[top2].min()\n",
    "balanced_df = pd.concat([\n",
    "    raw_dataset.df[raw_dataset.df['dx']==c].sample(min_ct, random_state=seed)\n",
    "    for c in top2\n",
    "]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "# Assign balanced df to raw_dataset\n",
    "raw_dataset.df = balanced_df\n",
    "raw_dataset.classes = top2\n",
    "raw_dataset.class_to_idx = {c:i for i,c in enumerate(top2)}\n",
    "\n",
    "# 2. Contrastive dataset with two augmentations\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.ds = dataset\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.ds[idx]\n",
    "        xi = self.transform(img)\n",
    "        xj = self.transform(img)\n",
    "        return xi, xj, label\n",
    "\n",
    "contrast_ds = ContrastiveDataset(raw_dataset, aug_transform)\n",
    "n = len(contrast_ds)\n",
    "train_n = int(0.8 * n)\n",
    "test_n  = n - train_n\n",
    "train_ds, test_ds = random_split(contrast_ds, [train_n, test_n],\n",
    "                                 generator=torch.Generator().manual_seed(seed))\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 3. Define SimCLR components\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim=128, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        feat_dim = self.encoder.fc.in_features\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.proj_head = ProjectionHead(feat_dim, hidden_dim, projection_dim)\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.proj_head(h)\n",
    "        return F.normalize(h, dim=1), F.normalize(z, dim=1)\n",
    "\n",
    "# NT-Xent loss\n",
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    N = z_i.size(0)\n",
    "    # concatenate embeddings\n",
    "    z = torch.cat([z_i, z_j], dim=0)  # 2N x D\n",
    "    # similarity matrix\n",
    "    sim_mat = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2) / temperature\n",
    "    # mask self-similarities\n",
    "    mask = torch.ones((2*N, 2*N), device=device) - torch.eye(2*N, device=device)\n",
    "    # exponentiate similarities\n",
    "    exp_sim = torch.exp(sim_mat) * mask\n",
    "    # denominator: sum over rows\n",
    "    denom = exp_sim.sum(dim=1)\n",
    "    # positive pairs: i->j and j->i\n",
    "    sim_ij = torch.exp(F.cosine_similarity(z_i, z_j) / temperature)\n",
    "    sim_ji = torch.exp(F.cosine_similarity(z_j, z_i) / temperature)\n",
    "    # compute loss\n",
    "    loss = -torch.log(sim_ij / denom[:N]) - torch.log(sim_ji / denom[N:])\n",
    "    return loss.mean()\n",
    "\n",
    "# 4. Train SimCLR encoder\n",
    "projection_dim = 4\n",
    "encoder = models.resnet18(weights=None).to(device)\n",
    "model   = SimCLR(encoder, projection_dim=projection_dim, hidden_dim=512).to(device)\n",
    "opt     = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs  = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tot_loss = 0\n",
    "    for xi, xj, _ in tqdm(train_loader, desc=f\"SimCLR Epoch {epoch+1}/{epochs}\"):\n",
    "        xi, xj = xi.to(device), xj.to(device)\n",
    "        _, zi = model(xi)\n",
    "        _, zj = model(xj)\n",
    "        loss = nt_xent_loss(zi, zj)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        tot_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {tot_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 5. Prepare evaluation dataset using basic_transform\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, metadata, image_dirs, transform, target_df):\n",
    "        self.df = target_df\n",
    "        self.image_dirs = image_dirs\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = raw_dataset.class_to_idx\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['image_id']\n",
    "        img_path = next((os.path.join(d, f\"{img_id}.jpg\") for d in image_dirs\n",
    "                         if os.path.isfile(os.path.join(d, f\"{img_id}.jpg\"))), None)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        lbl = self.class_to_idx[row['dx']]\n",
    "        return img, lbl\n",
    "\n",
    "# Build eval datasets matching train/test splits\n",
    "eval_dataset = EvalDataset(metadata_csv, image_dirs, basic_transform, balanced_df)\n",
    "train_idx = train_ds.indices\n",
    "test_idx  = test_ds.indices\n",
    "eval_train = Subset(eval_dataset, train_idx)\n",
    "eval_test  = Subset(eval_dataset, test_idx)\n",
    "eval_train_loader = DataLoader(eval_train, batch_size=32, shuffle=False, num_workers=4)\n",
    "eval_test_loader  = DataLoader(eval_test,  batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 6. Extract embeddings for eval sets\n",
    "def extract_embeddings(loader):\n",
    "    model.eval()\n",
    "    embs, lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Extract Embs\"):\n",
    "            imgs = imgs.to(device)\n",
    "            _, z = model(imgs)\n",
    "            embs.append(z.cpu()); lbls.append(labels)\n",
    "    return torch.cat(embs), torch.cat(lbls)\n",
    "\n",
    "train_embs, train_lbls = extract_embeddings(eval_train_loader)\n",
    "test_embs,  test_lbls  = extract_embeddings(eval_test_loader)\n",
    "\n",
    "# 7. Define and train linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes): super().__init__(); self.fc = nn.Linear(in_dim, num_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "clf   = LinearClassifier(projection_dim, 2).to(device)\n",
    "opt_c = optim.Adam(clf.parameters(), lr=1e-3)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "c_epochs = 5\n",
    "for e in range(c_epochs:=5):\n",
    "    clf.train(); tot=0; perm=torch.randperm(train_embs.size(0))\n",
    "    for i in range(0, len(perm), 32):\n",
    "        idx=perm[i:i+32]\n",
    "        out=clf(train_embs[idx].to(device))\n",
    "        loss=crit(out,train_lbls[idx].to(device))\n",
    "        opt_c.zero_grad(); loss.backward(); opt_c.step()\n",
    "        tot+=loss.item()\n",
    "    print(f\"Classifier Epoch {e+1}, Loss: {tot/(len(perm)/32):.4f}\")\n",
    "\n",
    "# 8. Evaluate classifier accuracy\n",
    "def eval_acc(loader):\n",
    "    clf.eval(); correct=total=0\n",
    "    with torch.no_grad():\n",
    "        for emb,label in loader:\n",
    "            preds=clf(emb.to(device)).argmax(dim=1).cpu()\n",
    "            correct+=(preds==label).sum().item()\n",
    "            total+=len(label)\n",
    "    return correct/total\n",
    "\n",
    "train_ld = DataLoader(torch.utils.data.TensorDataset(train_embs,train_lbls), batch_size=32)\n",
    "test_ld  = DataLoader(torch.utils.data.TensorDataset(test_embs, test_lbls),  batch_size=32)\n",
    "print(\"Train Acc:\", eval_acc(train_ld))\n",
    "print(\"Test  Acc:\", eval_acc(test_ld))\n",
    "\n",
    "# Class-wise accuracies\n",
    "def eval_per_class(loader, num_classes):\n",
    "    clf.eval()\n",
    "    correct = [0]*num_classes\n",
    "    total   = [0]*num_classes\n",
    "    with torch.no_grad():\n",
    "        for emb, label in loader:\n",
    "            preds = clf(emb.to(device)).argmax(dim=1).cpu()\n",
    "            for p, l in zip(preds, label):\n",
    "                total[l] += 1\n",
    "                if p == l:\n",
    "                    correct[l] += 1\n",
    "    return [correct[i]/total[i] if total[i]>0 else 0.0 for i in range(num_classes)]\n",
    "\n",
    "# Assuming two classes\n",
    "num_classes = 2\n",
    "train_cw = eval_per_class(train_ld, num_classes)\n",
    "test_cw  = eval_per_class(test_ld,  num_classes)\n",
    "\n",
    "# Map indices back to class names\n",
    "idx_to_class = {v:k for k,v in raw_dataset.class_to_idx.items()}\n",
    "train_cw_named = {idx_to_class[i]: train_cw[i] for i in range(num_classes)}\n",
    "test_cw_named  = {idx_to_class[i]: test_cw[i]  for i in range(num_classes)}\n",
    "\n",
    "print(\"Train class-wise accuracy:\", train_cw_named)\n",
    "print(\"Test  class-wise accuracy:\", test_cw_named)\n",
    "\n",
    "# 9. Save all embeddings and labels in a single NPZ file\n",
    "# Concatenate train and test embeddings and labels\n",
    "every_emb = torch.cat([train_embs, test_embs], dim=0)\n",
    "every_lbl = torch.cat([train_lbls, test_lbls], dim=0)\n",
    "# Convert to numpy arrays\n",
    "emb_np = every_emb.cpu().numpy()\n",
    "lbl_np = every_lbl.cpu().numpy()\n",
    "# Save to compressed NPZ\n",
    "output_file = 'ham10000_embeddings.npz'\n",
    "np.savez_compressed(output_file, embeddings=emb_np, labels=lbl_np)\n",
    "print(f\"Saved all embeddings and labels to {output_file} (compressed NPZ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d82de-0c46-4079-bff3-798ecd0a9f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
